#! /bin/bash
#SBATCH --job-name=img
#SBATCH --partition=kempner_dev
#SBATCH --account=kempner_dev
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=2
#SBATCH --cpus-per-task=16
#SBATCH --mem=128G
#SBATCH --time=1:00:00
#SBATCH --output=img-%N.%x.%j.out
#SBATCH --error=img-%N.%x.%j.err

module load cuda
module load cudnn
module load python

conda activate  /n/holylfs06/LABS/kempner_shared/Everyone/common_envs/miniconda3/envs/pytorch_image
export DATA_PATH="/n/holylfs06/LABS/kempner_shared/Everyone/testbed/vision/cifar10"


# Check and set N_GPUS_ON_NODE based on available SLURM variables
if [[ -n "$SLURM_GPUS_ON_NODE" ]]; then
    N_GPUS_ON_NODE=$SLURM_GPUS_ON_NODE
elif [[ -n "$SLURM_NTASKS_PER_NODE" ]]; then
    N_GPUS_ON_NODE=$SLURM_NTASKS_PER_NODE
elif [[ -n "$SLURM_NTASKS" ]]; then
    N_GPUS_ON_NODE=$SLURM_NTASKS
else
    echo "No relevant SLURM variables defined. Setting N_GPUS_ON_NODE to 0."
    N_GPUS_ON_NODE=0
fi


export GPUS_ON_NODE=$N_GPUS_ON_NODE
export NNODES=$SLURM_NNODES
WORLD_SIZE=$(($GPUS_ON_NODE*$NNODES))

nodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )
nodes_array=($nodes)
head_node=${nodes_array[0]}
head_node_ip=$(srun --nodes=1 --ntasks=1 -w "$head_node" hostname --ip-address)

for head_port in {29500..49000}; do ! nc -z localhost ${myport} && break; done
echo $head_port

export MASTER_ADDR=$head_node_ip
export MASTER_PORT=$head_port
echo "MASTER_ADDR MASTER_PORT WORLD_SIZE"
echo $MASTER_ADDR $MASTER_PORT $WORLD_SIZE


export CMD="torchrun \
    --nproc_per_node $GPUS_ON_NODE  --nnodes $NNODES \
    --rdzv_id=$SLURM_JOB_ID --rdzv_backend=c10d \
    --rdzv_endpoint $MASTER_ADDR:$MASTER_PORT \
    --max_restarts=3 \
   ./cifar10_ddp.py --data_path=$DATA_PATH \
   --batch_size 512 --num_epochs 20 --learning_rate 0.001  --sample_ratio 1.0
 "

echo $CMD 
srun -l $CMD

echo "Job Completed"

