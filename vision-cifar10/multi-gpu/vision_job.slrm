#! /bin/bash
#SBATCH --job-name=img
#SBATCH --partition=kempner_dev
#SBATCH --account=kempner_dev
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=4
#SBATCH --gres=gpu:4
#SBATCH --cpus-per-task=16
#SBATCH --mem=256G
#SBATCH --time=12:00:00
#SBATCH --output=img-%N.%x.%j.out
#SBATCH --error=img-%N.%x.%j.err


# Check and set N_GPUS_ON_NODE based on available SLURM variables
if [[ -n "$SLURM_GPUS_ON_NODE" ]]; then
    N_GPUS_ON_NODE=$SLURM_GPUS_ON_NODE
elif [[ -n "$SLURM_NTASKS_PER_NODE" ]]; then
    N_GPUS_ON_NODE=$SLURM_NTASKS_PER_NODE
elif [[ -n "$SLURM_NTASKS" ]]; then
    N_GPUS_ON_NODE=$SLURM_NTASKS
else
    echo "No relevant SLURM variables defined. Setting N_GPUS_ON_NODE to 0."
    N_GPUS_ON_NODE=0
fi


export GPUS_ON_NODE=$N_GPUS_ON_NODE
export NNODES=$SLURM_NNODES
export WORLD_SIZE=$(($GPUS_ON_NODE*$NNODES))

nodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )
nodes_array=($nodes)
head_node=${nodes_array[0]}
head_node_ip=$(srun --nodes=1 --ntasks=1 -w "$head_node" hostname --ip-address)

for head_port in {20000..30000}; do ! nc -z localhost ${myport} && break; done
echo $head_port

export MASTER_ADDR=$head_node_ip
export MASTER_PORT=$head_port
echo "MASTER_ADDR MASTER_PORT WORLD_SIZE"
echo $MASTER_ADDR $MASTER_PORT $WORLD_SIZE

CONTAINER_PATH=/n/holylabs/LABS/kempner_dev/Lab/containers/pytorch_2.1.2-cuda12.1-cudnn8-runtime.sif

export CMD="torchrun --nproc_per_node $GPUS_ON_NODE \
    --nnodes $NNODES \
    --rdzv_endpoint $MASTER_ADDR:$MASTER_PORT \
   ./torch_vision_ddp_cifar10.py
 "

echo $CMD 
srun -l singularity run --nv $CONTAINER_PATH $CMD

echo "Job Completed"

