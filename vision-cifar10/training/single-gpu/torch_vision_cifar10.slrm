#! /bin/bash
#SBATCH --job-name=img
#SBATCH --partition=<partition-name>
#SBATCH --account=<account-name>
#SBATCH --constraint=a100|h100
#SBATCH --requeue 
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=16
#SBATCH --mem=128G
#SBATCH --time=1:00:00
#SBATCH --output=img-%N.%x.%j.out
#SBATCH --error=img-%N.%x.%j.err


export DATA_PATH="/n/netscratch/kempner_dev/Everyone/workshop/ml-opt-workshop/data/cifar10"
export CONDA_ENV="/n/netscratch/kempner_dev/Everyone/workshop/ml-opt-workshop/shared_env/pytorch_image"
source ~/.ssh/wandb_key.sh

module load cuda
module load cudnn
module load python
conda activate $CONDA_ENV

export CMD="python torch_vision_cifar10.py \
  --data_path $DATA_PATH \
  --metrics_csv results.csv \
  --sample_ratio 1.0 \
  --batch_size 512 \
  --num_epochs 10 \
  --learning_rate 0.0005 \
  --model_name resnet50 \
  --mixed_precision auto \
  --pin_memory True \
  --use_checkpoint --checkpoint_path checkpoint.pth \
  --use_snapshot --snapshot_path snapshot.pth \
  --save_best_model --best_model_path best_model.pth \
  --export_onnx --onnx_path final_model.onnx \
  --use_wandb --wandb_mode online --wandb_project "optimize-ml-workflow"

 "

echo $CMD 

# Start time
start_time=$(date +%s)

eval $CMD
echo "Job Completed"

#End time
end_time=$(date +%s)

# Calculate the elapsed time
elapsed_time=$((end_time - start_time))

# Convert elapsed time to Hours:Minutes:Seconds format
hours=$((elapsed_time / 3600))
minutes=$(((elapsed_time % 3600) / 60))
seconds=$((elapsed_time % 60))

# Print the execution time
printf "Execution time : %02d:%02d:%02d\n" "$hours" "$minutes" "$seconds"


